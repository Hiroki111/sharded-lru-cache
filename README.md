# sharded-lru-cache

ğŸŒ Context & Usage
- The Users: Other backend services (e.g., a microservice needing to cache database results or API responses).
- The Use Case: High-throughput systems where a single global lock would become a bottleneck (e.g., a session store or a metadata cache).
- Scalability: * Throughput: Designed for 100k+ requests per second.
  - Data Volume: Typically gigabytes of RAM.
  - Payloads: Small to medium objects (JSON blobs, protobufs).

ğŸ› ï¸ Minimum Viable Product (MVP)
1. LRU Logic: A doubly linked list ğŸ”— combined with a hash map ğŸ—ºï¸ for $O(1)$ access and eviction.
2. Sharding Strategy: A hashing function (like fnv64a) to map keys to specific shards.
3. Concurrency Control: Using sync.RWMutex per shard to allow concurrent reads.
4. Basic API: Get(key), Set(key, value), and Delete(key).

ğŸš€ Optional Enhancements
- TTL (Time-to-Live): Automatically expiring keys after a duration.
- Prometheus Metrics: Tracking hit/miss ratios and eviction counts ğŸ“Š.
- Custom Serialization: Supporting gob or protobuf for cross-network compatibility.
- Distributed Layer: Adding a gRPC or HTTP interface to turn it into a standalone service.

```
/sharded-cache
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ lru/          # The core, non-thread-safe LRU logic
â”‚   â”‚   â”œâ”€â”€ lru.go
â”‚   â”‚   â””â”€â”€ lru_test.go
â”‚   â””â”€â”€ shard/        # The sharding layer and locking logic
â”‚       â”œâ”€â”€ manager.go
â”‚       â””â”€â”€ hasher.go
â”œâ”€â”€ pkg/              # Public API for users
â”‚   â””â”€â”€ cache.go
â”œâ”€â”€ main.go           # Example usage/CLI
â””â”€â”€ go.mod
```